---
layout: post
cover: assets/images/yoloventana.jpg
title: Deep Learning Datasets in the COVID era
date: 2020-05-28 12:00:00 +0545
categories: deep learning dataset database google
author: olaya
featured: true
summary: creating a dataset from internet images.
---

From 2020 I was expecting to collect a dataset for my Deep Learning PhD project,
but instead, 2020 brought me quarantine. This was quite frustrating because,
how can I keep going with my project, if I can't even make the first and more basic
step?

Well, I guess that once again, the answer is in the internet. Aren't there millions
of pictures on the internet that I can use to make my own database? Well, sure there are.
However, this idea arises some questions:

- Is there any tool that can help me with this? I could just google "cat pics"
(just to keep going with the typical cat example) and download the ones that fit my needs,
but that seems extremely time-consuming and ineffective.
- What about image rights? I'm not quite sure about the rights of using images
for a dataset, so I'll show you my findings on this in this post.

# Gathering Images for your database

Here, I would go through the most interesting methods I found to gather Images
from the internet (Google, Bing, and Flickr), to see which of them are suitable
for creating a Machine Learning database.

## From Google
Google is the most popular search engine, so no wonder that there are different
alternatives online to download pictures from it.

### Making custom scripts
The first solution I found for this was from the great blog
[pyimagesearch](https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/)
(seriously, is there any computer vision problem for which this blog doesn't
already have a solution?). I won't come into details since it is already clearly
explained in the original post, but I'll make a quick resume so you can get an idea
of how much human effort this solution requires. It can be basically divided in
three steps:

1. Search the query term on Google images.
2. Gather the URLs into a text file using the JavaScript console. You'll scroll
 through the results, and the script will simulate clicking on them and copying
 the URL for you.
3. Download the images from the URLs using a Python script.

This is indeed a very interesting solution. However, I see two inconvenients here:
First, you need to scroll through the results. It is not that much of a big deal,
but still would require your time on something that could be automated. And second,
although the google results are very good (and always improving) there are always
incorrect results  or duplicates on the results. Adrian proposes a manual search
for this cases, which will again consume your time and attention, but there is no
really a straightforward solution for this.

### Google Image downloaders

I found a bunch of python libraries like
[this](https://pypi.org/project/google_images_download/2.3.0/), or
[this one](https://pypi.org/project/googleimagedownloader/) that are supposed to
download pictures from Google Images with just a simple bash command or a shell
script. However, they recently stopped working.
The next workaround was a similar script,
[but this time for Bing](https://medium.com/@yfujiki/googleimagesdownload-is-dead-long-live-bingimagesdownload-fb9f5d3b4296).
But just like the others, it no longer works.

They all launch the same error: the images are not downloadable. There are
several Github issues around this problem, and it seems to be that the links
created by the scripts no longer work because Google has recently changed the
way they present the data (and I guess, same for Bing).

I'm sorry for the bad news, but I think this should be noted out to avoid you
from losing time by trying to make these libraries work. But don't worry,
hereafter I'm showing you the solutions that work!

### Simple Image Download
[This script](https://github.com/RiddlerQ/simple_image_download)
is pretty simple but is the only one that I found that works with Google up to date.
You basically define the Search query and the maximum number of pictures,
and it downloads them for you.

I tried it by downloading 200 pictures, and I'd say that up to this point
this is the best solution, since it is very straightforward and
it worked perfectly fine.


## Flickr Scraper
There's this similar alternative to the Google Images scripts, but
[with Flickr](https://github.com/ultralytics/flickr_scraper).
And yes, this one works!

You need a Flickr account in order to use it, and ask for permissions
(non-commercial in my case). They also ask you for data about your "app", and to
agree the API terms of use. Nobody likes making more accounts and accepting
more terms, and I agree with you in it being a headache, but I have to say that
in this case it's very convenient, because it will help us with the whole
"rights of use" thing.
I've read the terms (yes, I know), and by default the photos are owned
by the user that uploaded them. If the photo is marked as "All Rights Reserved",
the photo cannot be copied or used in any way without permission. So if you
want to use it, you must ask the owner for permission to do it.
The Flickr API has its own terms, but it clearly says that it use must
"comply with any other terms and conditions a user has attached to his or her
photo".
Unfortunately the Flickr Scraper doesn't filter which rights the image has,
however, since it is in the metadata of the image, maybe there is a way to
implement that.

So, to resume:

  :heavy_check_mark: FLickr Scraper works pretty easily and well.
  :x: however, it requires an user account
  :x: and it doesn't take into account the right permissions of the pictures.

 under construction -
